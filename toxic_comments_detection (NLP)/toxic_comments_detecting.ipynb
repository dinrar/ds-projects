{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Предварительные-операции\" data-toc-modified-id=\"Предварительные-операции-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Предварительные операции</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Создание-эмбеддингов-текстов\" data-toc-modified-id=\"Создание-эмбеддингов-текстов-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Создание эмбеддингов текстов</a></span></li><li><span><a href=\"#Подготовка-выборок-с-признаками-и-целевым-признаком\" data-toc-modified-id=\"Подготовка-выборок-с-признаками-и-целевым-признаком-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Подготовка выборок с признаками и целевым признаком</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Обучение-разных-моделей\" data-toc-modified-id=\"Обучение-разных-моделей-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение разных моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Сравнение-моделей\" data-toc-modified-id=\"Сравнение-моделей-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Сравнение моделей</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Выводы</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. Клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "**Цель:** обучить модель классификации комментариев на позитивные и негативные со значением метрики качества *F1* не меньше 0,75.\n",
    "\n",
    "Данные, на которых необходимо обучить модель: набор комментариев с разметкой токсичности правок (файл `toxic_comments.csv`: столбец *text* содержит текст комментария, а *toxic* — токсичность комментария, целевой признак)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительные операции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm import notebook\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл `toxic_comments.csv` и сохраним данные из файла в переменную `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение данных в датафрейме\n",
    "try:\n",
    "    # Ссылка на датасет, сохраненный на домашнем ноутбуке\n",
    "    df = pd.read_csv(\n",
    "        'D:\\\\YandexDisk\\\\Data science\\\\Яндекс. Практикум\\\\Спринт 13. Машинное обучение для текстов\\\\Проект\\\\toxic_comments.csv',\n",
    "        index_col=[0]\n",
    "    )\n",
    "except:\n",
    "# Ссылка на датасет, сохраненный на сервере Яндекс\n",
    "    df = pd.read_csv(\n",
    "        '/datasets/toxic_comments.csv',\n",
    "        index_col=[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим первые строки датафрейма, чтобы получить первое впечатление о них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим общую информацию о датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем долю пропусков в датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0.0\n",
       "toxic    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим статистические данные о датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>159292</td>\n",
       "      <td>159292</td>\n",
       "      <td>\", and welcome to Wikipedia! Thank you for you...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>159292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101612</td>\n",
       "      <td>0.302139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count  unique                                                top  \\\n",
       "text     159292  159292  \", and welcome to Wikipedia! Thank you for you...   \n",
       "toxic  159292.0     NaN                                                NaN   \n",
       "\n",
       "      freq      mean       std  min  25%  50%  75%  max  \n",
       "text     1       NaN       NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "toxic  NaN  0.101612  0.302139  0.0  0.0  0.0  0.0  1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датафрейме содержатся данные типов `object` (столбец `text`) и `int64` (столбец `toxic`).\n",
    "\n",
    "Столбец `text` содержит комментарии пользователей сервиса, а `toxic` - содержит данные о том, является ли комментарий допустимым или нет. Столбец `toxic` - целевой признак; значений класса `0` значительно больше, чем значений класса `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно можно сказать, что данных для выполнения проекта достаточно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание эмбеддингов текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для уменьшения времени выполнения расчетов из исходного корпуса возьмем только часть текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=3000, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим достаточно ли в новой выборке объектов класса `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.106333</td>\n",
       "      <td>0.308315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count      mean       std  min  25%  50%  75%  max\n",
       "toxic  3000.0  0.106333  0.308315  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания эмбеддингов используем предобученную модель RoBERTa (A Robustly Optimized BERT Pretraining Approach)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем токенайзер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенизацию текста в столбце `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 875 ms\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# токенизация\n",
    "df['encoded'] = df['text'].apply(\n",
    "  lambda x: tokenizer.encode(x, add_special_tokens=True)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учитывая ограничение на длину текста модеди BERT, ограничим длину закодированного текста 512 токенами - оставим 256 токенов из начала и 256 символов из конца закодированного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['encoded_max_len_512'] = df['encoded'].apply(\n",
    "  lambda x : x[:256]+x[len(x)-256:] if len(x) > 512 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим наибольшую длину закодированного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df['encoded_max_len_512'].apply(\n",
    "  lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для закодированного текста длиной меньше 512 токенов добавим нули для того, чтобы их длина равнялась 512 токенам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df['len'].max()\n",
    "df['padded'] = df['encoded_max_len_512'].apply(\n",
    "  lambda x: x + [0]*(n - len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим для закодированного текста маски внимания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attention_mask'] = df['padded'].apply(\n",
    "  lambda x: np.where(np.array(x) != 0, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель RoBERTa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним создание эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42517e170ddc4d2cbadb72ca174882f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "batch_size = 100 # по умолчанию 100\n",
    "embeddings = []\n",
    "\n",
    "padded = np.vstack(df['padded'])\n",
    "attention_mask = np.vstack(df['attention_mask'])\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    \n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    \n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(np.array(batch_embeddings[0]))\n",
    "\n",
    "embeddings = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка выборок с признаками и целевым признаком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на датафрейм, в котором содержатся признаки, и датафрейм, в котором содержатся целевые признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = embeddings\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датафрейм на обучающий, валидационный и тестовый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_valid, features_test, target_train_valid, target_test = (\n",
    "    train_test_split(features, target, test_size=0.25, stratify=target)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнена подготовка эмбеддингов для обучения моделей классификации и разделение выборки на обучающую, валидационную и тестовую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение разных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель дерева решений и оценим значение *F1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики f1 модели на обучающей выборке: 1.0\n",
      "Среднее значение метрики f1 модели на валидационной выборке: 0.753875901980163\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 49 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def cross_val_f1(features, target, blocks, clf_model):\n",
    "    \n",
    "    f1_train_scores = []\n",
    "    f1_valid_scores = []\n",
    "    features = pd.DataFrame(features)\n",
    "    target = target.reset_index(drop=True)\n",
    "    \n",
    "    sample_size = int(len(features)/blocks)\n",
    "       \n",
    "    for i in range(0, len(features), sample_size):\n",
    "        \n",
    "        train_indexes = pd.concat([features.iloc[:i], features.iloc[i + sample_size:]]).index\n",
    "        valid_indexes = features.iloc[i: i + sample_size].index\n",
    "        \n",
    "        # разобьем переменные features и target на выборки features_train, target_train, features_valid, target_valid\n",
    "        features_train = features.iloc[train_indexes].reset_index(drop=True)\n",
    "        target_train = target.iloc[train_indexes].reset_index(drop=True)\n",
    "\n",
    "        features_valid = features.iloc[valid_indexes].reset_index(drop=True)\n",
    "        target_valid = target.iloc[valid_indexes].reset_index(drop=True)\n",
    "        \n",
    "        model = clf_model\n",
    "        model = model.fit(features_train, target_train.values)\n",
    "        \n",
    "        f1_train_score = f1_score(target_train, model.predict(features_train))\n",
    "        f1_valid_score = f1_score(target_valid, model.predict(features_valid))\n",
    "        \n",
    "        f1_train_scores.append(f1_train_score)\n",
    "        f1_valid_scores.append(f1_valid_score)\n",
    "    \n",
    "    # рассчитаем среднее значение качества модели\n",
    "    print('Среднее значение метрики f1 модели на обучающей выборке:', np.mean(f1_train_scores))\n",
    "    print('Среднее значение метрики f1 модели на валидационной выборке:', np.mean(f1_valid_scores))\n",
    "    \n",
    "    return np.mean(f1_train_scores), np.mean(f1_valid_scores)\n",
    "    \n",
    "# выполнение функции\n",
    "decision_tree_train_f1, decision_tree_valid_f1 = cross_val_f1(\n",
    "    features_train_valid, target_train_valid, 3, DecisionTreeClassifier(class_weight='balanced', random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель случайного леса и оценим значение *f1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики f1 модели на обучающей выборке: 1.0\n",
      "Среднее значение метрики f1 модели на валидационной выборке: 0.8049979211998167\n",
      "CPU times: total: 3.66 s\n",
      "Wall time: 7.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random_forest_train_f1, random_forest_valid_f1 = cross_val_f1(\n",
    "    features_train_valid, target_train_valid, 3, RandomForestClassifier(random_state=1, class_weight='balanced', n_estimators=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии и оценим значение *f1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение метрики f1 модели на обучающей выборке: 0.7801064318523881\n",
      "Среднее значение метрики f1 модели на валидационной выборке: 0.7865103441831284\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logistic_regression_train_f1, logistic_regression_valid_f1 = cross_val_f1(\n",
    "    features_train_valid, target_train_valid, 3, LogisticRegression(C=5, class_weight='balanced', solver='saga', max_iter=2000, penalty='l2', random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем собранные данные в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ML model</th>\n",
       "      <th>f1 (train) value</th>\n",
       "      <th>f1 (test) value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegressionClassifier</th>\n",
       "      <td>0.780106</td>\n",
       "      <td>0.786510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ML model                      f1 (train) value  f1 (test) value\n",
       "RandomForestClassifier                1.000000         0.804998\n",
       "LogisticRegressionClassifier          0.780106         0.786510\n",
       "DecisionTreeClassifier                1.000000         0.753876"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'ML model':['f1 (train) value', 'f1 (test) value'],\n",
    "             'DecisionTreeClassifier':[decision_tree_train_f1, decision_tree_valid_f1],\n",
    "             'RandomForestClassifier':[random_forest_train_f1, random_forest_valid_f1],\n",
    "             'LogisticRegressionClassifier':[logistic_regression_train_f1, logistic_regression_valid_f1],\n",
    "             }).set_index('ML model').T.sort_values(by = ['f1 (test) value'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, наилучшее значение *f1* получено для модели случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучены 3 модели, наилучший результат получен для модели случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним определение метрики *f1* для модели случайного леса, обученной на обучающей и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение f1 на обучающей выборке : 1.0\n",
      "Значение f1 на тестовой выборке: 0.7651006711409397\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(random_state=1, class_weight='balanced', n_estimators=1000)\n",
    "best_model.fit(features_train_valid, target_train_valid)\n",
    "\n",
    "f1_train_score = f1_score(target_train_valid, best_model.predict(features_train_valid))\n",
    "f1_valid_score = f1_score(target_test, best_model.predict(features_test))\n",
    "\n",
    "print(f'Значение f1 на обучающей выборке : {f1_train_score}')\n",
    "print(f'Значение f1 на тестовой выборке: {f1_valid_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предварительной части были подготовлены эмбеддинги из части текстов исходного корпуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучены 3 модели классификации:\n",
    "* дерево решений;\n",
    "* случайный лес;\n",
    "* логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из критерия задания (наименьшее значение *f1*, не больше 0,75), выбрана наилучшая модель - модель случайного леса.\n",
    "\n",
    "Можно рекомендовать данную модель для выявления токсичных комментариев."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.883px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
